# -*- coding: utf-8 -*-
"""lrandomforest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lzOTP3oHx4LHLeRkOMeCgLnS8oJXjyiT

**ML Model,Load data**
"""

import pandas as pd
df=pd.read_csv("https://raw.githubusercontent.com/dataprofessor/data/refs/heads/master/delaney_solubility_with_descriptors.csv")
df

#data preparation
#DATA SEPARATION

y=df['logS']
y

X=df.drop('logS',axis=1)
X

#DATA SPLIT
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=100)

X_train

X_test

#linear regression model
from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(X_train,y_train)

y_train_pred=model.predict(X_train)
y_test_pred=model.predict(X_test)

y_train_pred

y_test_pred

from sklearn.metrics import mean_squared_error,r2_score
train_mse=mean_squared_error(y_train,y_train_pred)
train_r2=r2_score(y_train,y_train_pred)

test_mse=mean_squared_error(y_test,y_test_pred)
test_r2=r2_score(y_test,y_test_pred)

print('Train mse error',train_mse)
print('Train r2 error',train_r2)
print('Test mse error',test_mse)
print('Test r2 error',test_r2)

result=pd.DataFrame(['Linear regression',train_mse,train_r2,test_mse,test_r2]).transpose()
result.columns=['Method','Traning MSE','Training R2','Test MSE','Test R2']
result

"""**Random Forest**"""

from sklearn.ensemble import RandomForestRegressor
rf=RandomForestRegressor(max_depth=2,random_state=100)
rf.fit(X_train,y_train)

rf_train_pred=rf.predict(X_train)
rf_test_pred=rf.predict(X_test)

from sklearn.metrics import mean_squared_error

rf_train_mse=mean_squared_error(y_train,rf_train_pred)
rf_train_r2=r2_score(y_train,rf_train_pred)

rf_test_mse=mean_squared_error(y_test,rf_test_pred)
rf_test_r2=r2_score(y_test,rf_test_pred)

rf_result=pd.DataFrame(['Random forest',rf_train_mse,rf_train_r2,rf_test_mse,rf_test_r2]).transpose()
rf_result.columns=['Method','Traning MSE','Training R2','Test MSE','Test R2']
rf_result

# model comparison

df_models=pd.concat([result,rf_result],axis=0)
df_models

df_models.reset_index(drop=True)
df_models

#data visualization
import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(5,5))
plt.scatter(x=y_train,y=y_train_pred,c='#7CA500',alpha=0.3)

z=np.polyfit(y_train,y_train_pred,1)
p=np.poly1d(z)

plt.plot(y_train,p(y_train),'#F8766D')
plt.ylabel('Predict LogS')
plt.xlabel('Experimental LogS')

#example random forest
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
import numpy as np

# Train model
rf = RandomForestRegressor(
    n_estimators=200,
    random_state=42
)
rf.fit(X_train, y_train)

# Predictions
y_pred = rf.predict(X_test)

# Scatter plot
plt.figure()
plt.scatter(y_test, y_pred, alpha=0.2)

# Ideal line (y = x)
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())
plt.plot([min_val, max_val], [min_val, max_val])

plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Random Forest: Actual vs Predicted")
plt.show()